{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Teacher_Train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOStpyCeDY49YJX+Pr3tSeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kryuchkovdm/Distillation/blob/master/methods/Teacher_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3apKHpunCFas"
      },
      "source": [
        "def train_teacher(teacher,train_dataloader,optimizer):\n",
        "  train_loss_set = []\n",
        "  train_loss = 0\n",
        "  teacher.to(device)\n",
        "  # Переводим модель в training mode\n",
        "  teacher.train()\n",
        "\n",
        "  for step, batch in enumerate(tqdm(train_dataloader)):\n",
        "    # Переводим данные на видеокарту\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    # Обнуляем градиенты\n",
        "      optimizer.zero_grad()\n",
        "    \n",
        "    # Прогоняем данные по слоям нейросети\n",
        "      loss = teacher(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "      train_loss_set.append(loss[0].item())  \n",
        "    \n",
        "    # Обратный прогон\n",
        "      loss[0].backward()\n",
        "      torch.nn.utils.clip_grad_norm_(teacher.parameters(), 1.0)\n",
        "    # Шаг\n",
        "      optimizer.step()\n",
        "\n",
        "    # Обновляем loss\n",
        "      train_loss += loss[0].item()\n",
        "      # Empty cuda\n",
        "      del b_input_ids\n",
        "      del b_labels\n",
        "      del b_input_mask\n",
        "      torch.cuda.empty_cache()\n",
        "  print(f'Лосс на обучении: {train_loss / len(train_dataloader)}')\n",
        "  return train_loss / len(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs43ige7CdAD"
      },
      "source": [
        "def validate_teacher(validation_dataloader,teacher):\n",
        "    teacher.eval()\n",
        "\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in tqdm(validation_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            loss = teacher(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
        "            \n",
        "        total_eval_loss += loss[0].item()\n",
        "        del b_input_ids\n",
        "        del b_labels\n",
        "        del b_input_mask\n",
        "        torch.cuda.empty_cache()\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    \n",
        "    print(\"Лосс на тесте: {0:.2f}\".format(avg_val_loss))\n",
        "    return total_eval_loss / len(validation_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkG0uxF2Cmsm"
      },
      "source": [
        "def train_loop_teacher(model, optim, train_loader, test_loader, n_epochs=5, sched=None):\n",
        "    training_results = {\"epoch\": list(range(n_epochs)),\n",
        "                        \"train_loss\": [],                   \n",
        "                        \"test_loss\": []\n",
        "                        }\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    try:\n",
        "        for i in range(n_epochs):\n",
        "            \n",
        "            train_loss = train_teacher(model,train_loader, optimizer)\n",
        "            if sched is not None:\n",
        "                sched.step()\n",
        "            test_loss = validate_teacher(test_loader, model)\n",
        "            training_results[\"train_loss\"].append(train_loss)\n",
        "            training_results[\"test_loss\"].append(test_loss)\n",
        "    except KeyboardInterrupt:\n",
        "        pass\n",
        "\n",
        "    return pd.DataFrame(training_results)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}