{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO/onyzBLEp4bzSNuO2Mlwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kryuchkovdm/Distillation/blob/master/models/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MThIuC64BHuV"
      },
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_vocab,\n",
        "                 n_labels,\n",
        "                 embedding_dim=50,\n",
        "                 n_filters=100,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 dropout=0.5,\n",
        "                 special_chars=[],\n",
        "                 pretrained_embeddings=None):  \n",
        "        super(CNN, self).__init__()\n",
        "        self.n_vocab = n_vocab\n",
        "        self.n_labels = n_labels\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.n_filters = n_filters\n",
        "        self.filter_sizes = filter_sizes\n",
        "        self.dropout_p = dropout\n",
        "        self.width = len(filter_sizes) * n_filters\n",
        "\n",
        "        if pretrained_embeddings is not None:\n",
        "            assert n_vocab == pretrained_embeddings.shape[0]\n",
        "            assert embedding_dim == pretrained_embeddings.shape[1]\n",
        "            self.embedding = nn.Embedding.from_pretrained(pretrained_embeddings)\n",
        "        else:\n",
        "            self.embedding = nn.Embedding(n_vocab, embedding_dim)\n",
        "        \n",
        "        self.conv0 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=n_filters,\n",
        "                               kernel_size=(filter_sizes[0], embedding_dim))\n",
        "        self.conv1 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=n_filters,\n",
        "                               kernel_size=(filter_sizes[1], embedding_dim))\n",
        "        self.conv2 = nn.Conv2d(in_channels=1,\n",
        "                               out_channels=n_filters,\n",
        "                               kernel_size=(filter_sizes[2], embedding_dim))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.fc = nn.Linear(in_features=self.width, out_features=n_labels)\n",
        "\n",
        "        for special in special_chars:\n",
        "            self.embedding.weight.data[special] = torch.zeros(embedding_dim)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"Only input ids are required - kwargs are for API compat with BERT.\"\"\"\n",
        "        X = self.embedding(input_ids)\n",
        "        X = X.unsqueeze(1)  \n",
        "        X0 = F.relu(self.conv0(X).squeeze(3))\n",
        "        X1 = F.relu(self.conv1(X).squeeze(3))\n",
        "        X2 = F.relu(self.conv2(X).squeeze(3))\n",
        "        X0 = F.max_pool1d(X0, X0.shape[2]).squeeze(2)\n",
        "        X1 = F.max_pool1d(X1, X1.shape[2]).squeeze(2)\n",
        "        X2 = F.max_pool1d(X2, X2.shape[2]).squeeze(2)\n",
        "        X = torch.cat([X0, X1, X2], dim=1)\n",
        "        X = self.dropout(X)\n",
        "        X = self.fc(X)\n",
        "        return X"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}